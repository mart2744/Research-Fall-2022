{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64956198",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=DbESHcCoWbM&t=13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b98c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc54bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sphere data\n",
    "# define path\n",
    "path = \"/Users/maryclaremartin/Documents/Github/Research-Fall-2022/cali_camera_data\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "# empty array for image names\n",
    "image_names = []\n",
    "\n",
    "# add image names from directory to a list\n",
    "for image in dir_list:\n",
    "    image_names.append(image)\n",
    "\n",
    "# sort image titles\n",
    "image_names = sorted(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cdca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array for images, segmentation images\n",
    "images = []\n",
    "seg_images = []\n",
    "\n",
    "for image in image_names:\n",
    "    if \"img\" in image:\n",
    "        images.append(Image.open(os.path.join(path,image)))\n",
    "    elif \"seg\" in image:\n",
    "        seg_images.append(Image.open(os.path.join(path,image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65290867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "class sphereDataset(Dataset):\n",
    "    def __init__(self, seg_images, images, transform=transforms.ToTensor(), target_transform=transforms.ToTensor()):\n",
    "        self.seg_images = seg_images\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seg_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = images[idx]\n",
    "        seg = seg_images[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            seg = self.target_transform(seg)\n",
    "        return image, seg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c5019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3,1,1)\n",
    "        #self.l1 = nn.Linear(800 * 600, 64)\n",
    "        #self.l2 = nn.Linear(64, 64)\n",
    "        #self.l3 = nn.Linear(800 * 600,10)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #h1 = nn.functional.relu(self.l1(x))\n",
    "        #h2 = nn.functional.relu(self.l2(h1))\n",
    "        #logits = self.l3(h2)\n",
    "        logits = nn.functional.relu(self.conv(x))\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=1e-2) \n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        # flatten\n",
    "        #b = x.size(0)\n",
    "        #print('b:', b)\n",
    "        #x = x.view(b, -1)\n",
    "        \n",
    "        #c = y.size(0)\n",
    "        #y = y.view(c, -1)\n",
    "        \n",
    "        # forward\n",
    "        logits = self(x)\n",
    "        \n",
    "        # compute the objective function\n",
    "        J = self.loss(logits, y)\n",
    "        \n",
    "        return J\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_data = sphereDataset(seg_images, images)\n",
    "        train_loader = DataLoader(train_data, batch_size=1)\n",
    "        return train_loader\n",
    "    \n",
    "model = ImageClassifier()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81260006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type             | Params\n",
      "------------------------------------------\n",
      "0 | conv | Conv2d           | 4     \n",
      "1 | loss | CrossEntropyLoss | 0     \n",
      "------------------------------------------\n",
      "4         Trainable params\n",
      "0         Non-trainable params\n",
      "4         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/maryclaremartin/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:225: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635699bcf48040f488b0e016df99150b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = 10)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779c917",
   "metadata": {},
   "source": [
    "random stuff for figuring out sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f79dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset\n",
    "sphereDataset = sphereDataset(seg_images, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726bc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sphereDataLoader = DataLoader(sphereDataset, batch_size = 5, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cc99ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = next(iter(sphereDataLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "759f5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84925f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de7604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv2d(3,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edebea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64b0379a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 598, 798])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a1c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
